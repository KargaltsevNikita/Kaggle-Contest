{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загрузим необходимые библиотеки\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from src.category_tree.category_tree import CategoryTree\n",
    "import requests\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Зададим константы\n",
    "RANDOM_STATE = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загрузим иерархию категорий\n",
    "category_tree = CategoryTree(category_tree_path='data/raw/category_tree.csv')\n",
    "categor = pd.read_csv('data/raw/category_tree.csv')\n",
    "\n",
    "# Загрузим ошибочно размеченные примеры\n",
    "df = pd.read_parquet('data/processed/bad_labeled.parquet', columns=['source_name', 'cat_id', 'hash_id'])\n",
    "\n",
    "# Отфильтруем только те примеры, которые относятся к категориям на уровне перед листом в дереве\n",
    "pre_leaf_nodes = set(categor[categor.cat_id.isin(category_tree.leaf_nodes)].parent_id.to_list())\n",
    "df = df[df.cat_id.isin(pre_leaf_nodes)]\n",
    "\n",
    "# Перемешаем отфильтрованные данные случайным образом, чтобы избежать последовательных закономерностей\n",
    "df = df.sample(frac=1,random_state=RANDOM_STATE).reset_index(drop=True)\n",
    "\n",
    "# Добавим текстовые названия категорий к данным\n",
    "df = df.merge(categor, on='cat_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4181, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Пытаемся загрузить ранее сохраненный прогресс обработки данных\n",
    "try:\n",
    "    df_save = pd.read_csv('data/processed/bad_labeled_qwen2.5:3b.csv')\n",
    "except FileNotFoundError:\n",
    "    # Если файл не найден\n",
    "    df_save = pd.DataFrame(columns=['hash_id', 'source_name', 'pred_cat_id'])\n",
    "df_save.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:59<00:00,  3.11s/it]\n"
     ]
    }
   ],
   "source": [
    "# Настройки Ollama\n",
    "OLLAMA_URL = 'http://127.0.0.1:13537/api/chat'\n",
    "MODEL_NAME = 'qwen2.5:3b'\n",
    "\n",
    "def ask_ollama(prompt, history=[]):\n",
    "    \n",
    "    try:\n",
    "        response = requests.post(OLLAMA_URL, json={\n",
    "            'model': MODEL_NAME,\n",
    "            'messages': history + [{'role': 'user', 'content': prompt}],\n",
    "            'temperature': 0.2,\n",
    "            'stream': False\n",
    "        })\n",
    "        response.raise_for_status()\n",
    "        return response.json()['message']['content'].strip()\n",
    "    except Exception as e:\n",
    "        print(f\"Error requesting Ollama: {e}\")\n",
    "        return None\n",
    "\n",
    "# Подготовим данные\n",
    "start_categor = categor[categor['parent_id'].isna()]['cat_name'].tolist()\n",
    "categor_dict = categor.groupby('parent_id')['cat_name'].apply(list).to_dict()\n",
    "\n",
    "# Вытаскиваем нужные колонки из датафрейма df\n",
    "source_name_list = df['source_name'].tolist()\n",
    "hash_id_list = df['hash_id'].tolist()\n",
    "cat_name_list = df['cat_name'].tolist()\n",
    "cat_id_list = df['cat_id'].tolist()\n",
    "\n",
    "# Создадим список для хранения прогнозов\n",
    "cat_id_pred = []\n",
    "\n",
    "# Определим начальный индекс для обработки\n",
    "start_index = df_save.shape[0]\n",
    "count = 0 \n",
    "\n",
    "for name, hash_id, cat_name, cat_id in tqdm(\n",
    "    zip(source_name_list[start_index:], hash_id_list[start_index:], cat_name_list[start_index:], cat_id_list[start_index:]), \n",
    "    total=len(source_name_list[start_index:])\n",
    "):\n",
    "    count += 1\n",
    "\n",
    "    # Найдем подкатегорию для текущей категории\n",
    "    subcategories = categor_dict.get(cat_id, [])\n",
    "\n",
    "    # Отформатируем список подкатегорий в виде строки\n",
    "    lst = '\\n - ' + '\\n - '.join(subcategories)\n",
    "    cat = cat_name\n",
    "\n",
    "    # Инициализируем журнал разговоров с помощью системных инструкций\n",
    "    chat_history = [{\n",
    "        'role': 'system',\n",
    "        'content': (\n",
    "            'Ты полезный помощник по определению категории товара и списка категорий, который строго следует инструкции. '\n",
    "            'Ты всегда выбираешь только одну категорию из предложенного списка, без лишних слов.'\n",
    "        )\n",
    "    }]\n",
    "\n",
    "    prompt = (\n",
    "        f\"Товар: '{name}'.\\n\"\n",
    "        f\"Текущая категория: {cat}.\\n\"\n",
    "        f\"Выбери наиболее подходящую подкатегорию из списка:\\n{lst}\\n\"\n",
    "        f\"Ответ должен быть строго только названием категории из списка, без лишних слов.\"\n",
    "    )\n",
    "\n",
    "    answer = ask_ollama(prompt, chat_history)\n",
    "    if not answer:\n",
    "        # Если запрос Ollama завершается неудачей, добавьте результат сбоя и прервем цикл\n",
    "        cat_id_pred.append([hash_id, name, None])\n",
    "        break\n",
    "\n",
    "    # Удалим лишние символы\n",
    "    answer = answer.strip().strip('.')\n",
    "\n",
    "    chat_history.append({'role': 'user', 'content': prompt})\n",
    "    chat_history.append({'role': 'assistant', 'content': answer})\n",
    "\n",
    "    # Найдем идентификатор подкатегории на основе ответа Олламы\n",
    "    mask = (categor['cat_name'] == answer) & (categor['parent_id'] == cat_id)\n",
    "    category = categor.loc[mask]\n",
    "\n",
    "    if category.empty:\n",
    "        cat_id_pred.append([hash_id, name, np.nan])\n",
    "    else:\n",
    "        cat_id_pred.append([hash_id, name, answer])\n",
    "\n",
    "    # Сохраняем прогресс каждые 10 шагов\n",
    "    if count % 10 == 0:\n",
    "        df_save = pd.concat([df_save, pd.DataFrame(cat_id_pred, columns=['hash_id', 'source_name', 'pred_cat_id'])])\n",
    "        df_save.to_csv('data/processed/bad_labeled_qwen2.5:3b.csv', index=False, na_rep='NaN')\n",
    "        cat_id_pred = []\n",
    "\n",
    "    if count % 1000 == 0:\n",
    "        print(df_save.shape)\n",
    "\n",
    "# Сохраним все оставшиеся прогнозы\n",
    "if cat_id_pred:\n",
    "    df_save = pd.concat([df_save, pd.DataFrame(cat_id_pred, columns=['hash_id', 'source_name', 'pred_cat_id'])])\n",
    "    df_save.to_csv('data/processed/bad_labeled_qwen2.5:3b.csv', index=False, na_rep='NaN')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
